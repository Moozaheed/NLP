{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Matching\n",
        "The Matcher find words and phrases using rules describing their token attributes. Rules can refer to token annotations (like the text or part-of-speech tags), as well as lexical attributes like **Token.is_punct**. Applying the matcher to a Doc gives you access to the matched tokens in context. [For more](https://spacy.io/api/matcher/). To make patterns click [here](https://demos.explosion.ai/matcher).\n",
        "\n"
      ],
      "metadata": {
        "id": "dnn8KUdHKqeT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqLTvmYKpYC"
      },
      "outputs": [],
      "source": [
        "# Creating Pattern\n",
        "pattern_1 = [{'LOWER': 'helllo'},{'LOWER': 'world'}]\n",
        "pattern_2 = [{'LOWER': 'hello'},{'IS_PUNCT': True},{'LOWER': 'world'}]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule-Based Matching**\n",
        "Compared to using regular expressions on raw text. It also give access to the tokens within the document and their relationships. This means we can easily access and analyze the surrounding tokens, merge spans into single tokens or add entries to the named entities in **doc.ents**. [For more](https://spacy.io/usage/rule-based-matching). \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-tWggNeKNX3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "dwiy25dfOETN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher=Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "rIQpA-qDOGUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add patterns to matcher object\n",
        "# Add a match rule to matcher, A match rule consists of,\n",
        "# 1) An ID key\n",
        "# 2) pattern\n",
        "matcher.add('Hello World',[pattern_2])"
      ],
      "metadata": {
        "id": "jHxdK5idOISN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a document\n",
        "doc = nlp(\" Hello World nor ld' are the first two printed words for most of the programers, printing 'Hello—World' most for beginners\")"
      ],
      "metadata": {
        "id": "oT290qm0OgXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the matches"
      ],
      "metadata": {
        "id": "LaA9nICGOkc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches=matcher(doc)\n",
        "print(find_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQLsMv4vPHwU",
        "outputId": "f1fd4be8-91b4-452a-b980-d940db1d8757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8585552006568828647, 20, 23)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id,start,end in find_matches:\n",
        "  string_id =nlp.vocab.strings[match_id]\n",
        "  span=doc[start:end]\n",
        "  print(match_id,string_id,start,end,span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl8cUithPRmU",
        "outputId": "b685ca34-bd9a-489a-90ba-fe6f211d28fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8585552006568828647 Hello World 20 23 Hello—World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase Matching**\n",
        " If we need to match large terminology lists, we can also use the PhraseMatcher and create Doc objects instead of token patterns, which is much more efficient overall. The Doc patterns can contain single or multiple tokens."
      ],
      "metadata": {
        "id": "7H5gN9jcN9kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "2m0gGLEJQK0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher= PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "3jhzGfwGQMna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_list=[\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]"
      ],
      "metadata": {
        "id": "Z0caPWkMQNxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_patterns=[nlp(text) for text in phrase_list]"
      ],
      "metadata": {
        "id": "GD2rr7sQQPtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_patterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhgjM1DEQRI5",
        "outputId": "75358e24-05d8-4d22-ab63-ce42aa654a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Barack Obama, Angela Merkel, Washington, D.C.]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(phrase_patterns[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQqwg8oxQSHY",
        "outputId": "e571fa38-43f0-48e7-a32d-cc9fe4883174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add(\"TerminologyList\",None,*phrase_patterns)"
      ],
      "metadata": {
        "id": "waR4xj9UQTuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_3 = nlp(\" German Chancellor Angela Merkel and US President Barack Obama \"\n",
        "      \" converse in the Oval Office inside the White House in Washington, D.C. \")"
      ],
      "metadata": {
        "id": "XlzvhZKkQVMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_matches = matcher(doc_3)\n",
        "print(find_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GolSOIk-QWb3",
        "outputId": "e3f52e43-d020-418b-cdbb-607a9c60b62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3766102292120407359, 3, 5), (3766102292120407359, 8, 10), (3766102292120407359, 21, 24)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id,start,end in find_matches:\n",
        "  string_id =nlp.vocab.strings[match_id]\n",
        "  span=doc[start:end]\n",
        "  print(match_id,string_id,start,end,span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acNxQDcbQaDO",
        "outputId": "d19774d1-c367-4866-b428-49381c10e92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3766102292120407359 TerminologyList 3 5 nor ld\n",
            "3766102292120407359 TerminologyList 8 10 first two\n",
            "3766102292120407359 TerminologyList 21 24 —World'\n"
          ]
        }
      ]
    }
  ]
}